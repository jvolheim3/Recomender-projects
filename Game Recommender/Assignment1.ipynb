{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1  \n",
    "\n",
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f55c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005c1a02-c5bf-4241-8d00-dc260d36f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2abe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54fa48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27aec54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72d24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "allHours = []\n",
    "for l in readJSON(\"./Data/train.json.gz\"):\n",
    "    allHours.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462bd9bd-b657-4571-8fef-eee11d852099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('u00914251',\n",
       " 'g61913894',\n",
       " {'hours': 17.1,\n",
       "  'text': 'This is the perfect gift for my friend!!!',\n",
       "  'gameID': 'g61913894',\n",
       "  'hours_transformed': 4.177917792195843,\n",
       "  'early_access': False,\n",
       "  'user_id': '76561198116282623',\n",
       "  'date': '2017-12-24',\n",
       "  'userID': 'u00914251'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoursTrain = allHours[:165000]\n",
    "hoursValid = allHours[165000:]\n",
    "hoursValid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fd9e5-0ba6-4fef-83c1-315503d75348",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e06cc33-bc60-4b45-be63-8033c17d9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any other preprocessing...\n",
    "gamesPerUser = {}\n",
    "UserPerGame = {}\n",
    "for u,g,d in hoursTrain:\n",
    "    if u not in gamesPerUser:\n",
    "        gamesPerUser[u] = [g]\n",
    "    else:\n",
    "        gamesPerUser[u].append(g)\n",
    "    if g not in UserPerGame:\n",
    "        UserPerGame[g] = [u]\n",
    "    else:\n",
    "        UserPerGame[g].append(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa30a66-0dcd-4f1f-beb0-a6ba473c9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to randomly select a game that a user hasn't played\n",
    "def ranGame(user):\n",
    "    '''random game user hasnt played'''\n",
    "    ran = random.choice(list(UserPerGame.keys()))\n",
    "    \n",
    "    # Check if the user hasn't played any games\n",
    "    if user not in gamesPerUser:\n",
    "        return ran\n",
    "\n",
    "    # Check if the user has played all the games\n",
    "    if len(gamesPerUser[user]) == len(UserPerGame):\n",
    "        print('all games played')\n",
    "        return ran\n",
    "    \n",
    "    # Keep selecting a random game until it is one that the user hasn't played\n",
    "    while ran in gamesPerUser[user]:\n",
    "        ran = random.choice(list(UserPerGame.keys()))\n",
    "    return ran\n",
    "    \n",
    "# Create a new list to store the modified validation hours\n",
    "newHoursValid = []\n",
    "for u,g,d in hoursValid:\n",
    "    newHoursValid.append((u,g,1))\n",
    "    newHoursValid.append((u,ranGame(u),0))\n",
    "\n",
    "# Create a new list to store the modified training hours\n",
    "newHoursTrain = []\n",
    "for u,g,d in hoursTrain:\n",
    "    newHoursTrain.append((u,g,1))\n",
    "    newHoursTrain.append((u,ranGame(u),0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute most popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a defaultdict to count the number of times each game is played\n",
    "gameCount = defaultdict(int)\n",
    "# Initialize a variable to keep track of the total number of games played\n",
    "totalPlayed = 0\n",
    "\n",
    "# Iterate over the training hours\n",
    "for user, game, _ in hoursTrain:\n",
    "  # Increment the count for the current game\n",
    "  gameCount[game] += 1\n",
    "  # Increment the total number of games played\n",
    "  totalPlayed += 1\n",
    "\n",
    "# Create a list of tuples containing the game count and game ID\n",
    "mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "# Sort the list in descending order based on the game count\n",
    "mostPopular.sort(reverse=True)\n",
    "\n",
    "# Create a set to store the most popular games\n",
    "return1 = set()\n",
    "# Initialize a variable to keep track of the cumulative game count\n",
    "count = 0\n",
    "\n",
    "# Iterate over the sorted list of most popular games\n",
    "for ic, i in mostPopular:\n",
    "  # Add the game ID to the set of most popular games\n",
    "  return1.add(i)\n",
    "  # Increment the cumulative game count\n",
    "  count += ic\n",
    "  # Check if the cumulative game count exceeds the threshold (68.6868% of total games played)\n",
    "  if count > totalPlayed * 0.686868686868687:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e7cca75-8730-459c-ad27-d827d65856e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Jaccard similarity between two sets\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))  # Calculate the intersection of the two sets\n",
    "    denom = len(s1.union(s2))  # Calculate the union of the two sets\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom  # Return the Jaccard similarity coefficient\n",
    "\n",
    "# Function to calculate the similarity between a user and a game\n",
    "def similar(u, g, s=1):\n",
    "    siml = []\n",
    "    for i in gamesPerUser[u]:\n",
    "        if i == g:\n",
    "            continue\n",
    "        if g in return1:\n",
    "            siml.append(Jaccard(set(UserPerGame[g]), set(UserPerGame[i])) * s)\n",
    "        else:\n",
    "            siml.append(Jaccard(set(UserPerGame[g]), set(UserPerGame[i])))\n",
    "    if len(siml) == 0:\n",
    "        return 0\n",
    "\n",
    "    siml.sort(reverse=True)\n",
    "\n",
    "    if len(siml) // 2 > 1:\n",
    "        siml = siml[:len(siml) // 2]\n",
    "    else:\n",
    "        return siml[0]\n",
    "\n",
    "    simAvg = sum(siml) / len(siml)\n",
    "    return simAvg\n",
    "\n",
    "# Function to calculate the similarity between a user and all games in the training set\n",
    "def getTrainSim(s=1):\n",
    "    sim3 = []\n",
    "\n",
    "    for u, g, _ in newHoursTrain:\n",
    "        if u not in gamesPerUser:\n",
    "            sim3.append(0)\n",
    "        else:\n",
    "            sim3.append(similar(u, g, s))\n",
    "    return sim3\n",
    "\n",
    "# Function to calculate the similarity between a user and all games in the validation set\n",
    "def getValidSim(s=1):\n",
    "    sim3 = []\n",
    "\n",
    "    for u, g, _ in newHoursValid:\n",
    "        if u not in gamesPerUser:\n",
    "            sim3.append(0)\n",
    "        else:\n",
    "            sim3.append(similar(u, g, s))\n",
    "    return sim3\n",
    "\n",
    "# Function to train the model by finding the best threshold value\n",
    "def trainModel(thres_start=0.009, thres_end=0.04, N_Tstep=500, s_start=1, s_end=1.1, N_Sstep=3):\n",
    "    sim1 = getTrainSim()\n",
    "    print('training model: Thresholds')\n",
    "\n",
    "    best_threshold = 0\n",
    "    best_acc = 0\n",
    "    y_actual = [d for _, _, d in newHoursTrain]\n",
    "    for thres in np.linspace(thres_start, thres_end, N_Tstep):\n",
    "        y_pred = np.array(sim1) > thres\n",
    "        acc = sum(y_pred == y_actual) / len(y_actual)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = thres\n",
    "\n",
    "    print('best threshold: ', best_threshold, 'Acc: ', best_acc)\n",
    "\n",
    "    return best_threshold\n",
    "\n",
    "# Function to validate the model using a given threshold value\n",
    "def validateModel(thres):\n",
    "    sim1 = getValidSim()\n",
    "    y_actual = [d for _, _, d in newHoursValid]\n",
    "    y_pred = np.array(sim1) > thres\n",
    "    acc = sum(y_pred == y_actual) / len(y_actual)\n",
    "    print('Accuracy: ', acc)\n",
    "    return acc\n",
    "\n",
    "# Function to predict whether a user will play a game based on similarity and threshold values\n",
    "def predict(u, g, s=1, thres=0.001):\n",
    "    if u not in gamesPerUser:\n",
    "        return 0\n",
    "    sim = similar(u, g, s)\n",
    "    if sim > thres:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: Thresholds\n",
      "best threshold:  0.01744889779559118 Acc:  0.8678060606060606\n",
      "best_threshold:  0.01744889779559118\n",
      "Accuracy:  0.7075707570757076\n",
      "0.7075707570757076\n"
     ]
    }
   ],
   "source": [
    "best_threshold =trainModel()\n",
    "print( 'best_threshold: ', best_threshold)\n",
    "print(validateModel(best_threshold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features for logistic regression\n",
    "def feature(u, g):\n",
    "    feat = [1, predict(u, g, 1, 0.0173)]  # Add bias term and similarity prediction\n",
    "    feat.append(gameCount[g] / totalPlayed if g in return1 else 0)  # Add popularity feature\n",
    "    return feat\n",
    "\n",
    "# Create feature matrix X and target vector y for logistic regression\n",
    "X = [feature(u, g) for u, g, _ in newHoursTrain]\n",
    "y = [d for _, _, d in newHoursTrain]\n",
    "\n",
    "# Initialize a logistic regression classifier with balanced class weights\n",
    "clf = linear_model.LogisticRegression(class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model:\n",
      "Logistic Regression Accuracy:  0.8676515151515152\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Model:')\n",
    "clf.fit(X, y)\n",
    "print('Logistic Regression Accuracy: ', clf.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on Validation Set:  0.7086708670867087\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix X_valid and target vector Y_valid_actual for validation set\n",
    "X_valid = [feature(u,g) for u,g,_ in newHoursValid]\n",
    "Y_valid_actual = [d for _,_,d in newHoursValid]\n",
    "\n",
    "# Print the accuracy of the logistic regression model on the validation set\n",
    "print('Logistic Regression Accuracy on Validation Set: ', clf.score(X_valid,Y_valid_actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75f81286-487d-494a-8ee8-a42c1aca6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Played.csv\", 'w')\n",
    "pred = []\n",
    "for l in open(\"./Data/pairs_Played.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        \n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    pred = clf.predict([feature(u,g)])[0]\n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: hours played prediction \n",
    "### Preprocessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to map user and item IDs to numerical indices\n",
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "\n",
    "# Create a list to store the interactions between users, items, and hours played\n",
    "interactions = []\n",
    "\n",
    "# Iterate over all the hours data\n",
    "for u, g, d in allHours:\n",
    "    # Map user IDs to numerical indices\n",
    "    if u not in userIDs:\n",
    "        userIDs[u] = len(userIDs)\n",
    "    \n",
    "    # Map item IDs to numerical indices\n",
    "    if g not in itemIDs:\n",
    "        itemIDs[g] = len(itemIDs)\n",
    "    \n",
    "    # Append the interaction to the list, including the transformed hours played\n",
    "    interactions.append((u, g, d['hours_transformed']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the interactions into training and test sets\n",
    "nTrain = int(len(interactions) * 0.75)\n",
    "interactionsTrain = interactions[:nTrain]\n",
    "interactionsTest = interactions[nTrain:]\n",
    "\n",
    "# Extract the hours played from the training set\n",
    "trainHours = [r for u,i,r in interactionsTrain]\n",
    "\n",
    "# Calculate the global average of hours played\n",
    "globalAverage = sum(trainHours) * 1.0 / len(trainHours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to store the items per user and users per item\n",
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "\n",
    "# Create dictionaries to store the hours per user and hours per item\n",
    "hoursPerUser = defaultdict(set)\n",
    "hoursPerItem = defaultdict(set)\n",
    "\n",
    "# Iterate over the training interactions\n",
    "for u, i, r in interactionsTrain:\n",
    "    # Append the item to the list of items for the current user\n",
    "    itemsPerUser[u].append(i)\n",
    "    \n",
    "    # Append the user to the list of users for the current item\n",
    "    usersPerItem[i].append(u)\n",
    "\n",
    "# Iterate over the training interactions\n",
    "for u, i, d in interactionsTrain:\n",
    "    # Extract the hours from the interaction\n",
    "    hours = d\n",
    "    \n",
    "    # Add the user and hours to the set of hours for the current item\n",
    "    hoursPerItem[i].add((u, hours))\n",
    "    \n",
    "    # Add the item and hours to the set of hours for the current user\n",
    "    hoursPerUser[u].add((i, hours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the rating for a user-item pair\n",
    "def predict(u, g):\n",
    "    global alpha\n",
    "    global betaU\n",
    "    global betaI\n",
    "    \n",
    "    bu = 0\n",
    "    bi = 0\n",
    "    if u in betaU:\n",
    "        bu = betaU[u]\n",
    "    if g in betaI:\n",
    "        bi = betaI[g]\n",
    "    return alpha + bu + bi\n",
    "\n",
    "# Function to calculate the mean squared error (MSE) on the validation set\n",
    "def mseValidate():\n",
    "    mse = 0\n",
    "    for u, g, r in interactionsTest:\n",
    "        prediction = predict(u, g)\n",
    "        mse += (r - prediction) ** 2\n",
    "    mse /= len(interactionsTest)\n",
    "    return mse\n",
    "\n",
    "# Function to perform one iteration of the training process with separate regularization terms for betaU and betaI\n",
    "def iterate(lami, lamu, lr):\n",
    "    global alpha\n",
    "    global betaU\n",
    "    global betaI\n",
    "    lalpha = alpha\n",
    "    lbetaU = betaU.copy()\n",
    "    lbetaI = betaI.copy()\n",
    "\n",
    "    # Update alpha\n",
    "    a = sum(r - (betaU[u] + betaI[i]) for u, i, r in interactionsTrain)\n",
    "    b = a / len(interactionsTrain)\n",
    "    alpha = lalpha + lr * (b - lalpha)\n",
    "\n",
    "    # Update betaU\n",
    "    for u in hoursPerUser:\n",
    "        sm = sum(i[1] - (alpha + betaI[i[0]]) for i in hoursPerUser[u])\n",
    "        sm = sm / (lamu + len(hoursPerUser[u]))\n",
    "        betaU[u] = lbetaU[u] + lr * (sm - lbetaU[u])\n",
    "\n",
    "    # Update betaI\n",
    "    for u in hoursPerItem:\n",
    "        sm = sum(i[1] - (alpha + betaU[i[0]]) for i in hoursPerItem[u])\n",
    "        sm = sm / (lami + len(hoursPerItem[u]))\n",
    "        betaI[u] = lbetaI[u] + lr * (sm - lbetaI[u])\n",
    "        \n",
    "    # Calculate MSE on the training set\n",
    "    mse = 0\n",
    "    for u, g, r in interactionsTrain:\n",
    "        prediction = alpha + betaU[u] + betaI[g]\n",
    "        mse += (r - prediction) ** 2\n",
    "        \n",
    "    # Calculate the regularization terms\n",
    "    regularizeru = 0\n",
    "    regularizeri = 0\n",
    "    for u in betaU:\n",
    "        regularizeru += betaU[u] ** 2\n",
    "    for g in betaI:\n",
    "        regularizeri += betaI[g] ** 2\n",
    "\n",
    "    mse /= len(interactionsTrain)\n",
    "    return mse, mse + lamu * regularizeru + lami * regularizeri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find lambda combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "\n",
    "# Iterate over different lambda values for regularization\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        print('lamda: ', i, 'lamu: ', j)\n",
    "        \n",
    "        # Initialize betaU and betaI dictionaries\n",
    "        betaU = {}\n",
    "        betaI = {}\n",
    "        \n",
    "        # Set initial values for betaU and betaI\n",
    "        for u in hoursPerUser:\n",
    "            betaU[u] = 0\n",
    "        for g in hoursPerItem:\n",
    "            betaI[g] = 0\n",
    "        \n",
    "        # Set initial value for alpha as the global average\n",
    "        alpha = globalAverage \n",
    "        \n",
    "        mse, objective = (100, 100)\n",
    "        newMSE, newObjective = iterate(i, j, 0.78)\n",
    "        itera = 0\n",
    "        \n",
    "        # Perform iterations until convergence or maximum number of iterations reached\n",
    "        while itera < 10 or objective - newObjective > 0.01:\n",
    "            mse, objective = newMSE, newObjective\n",
    "            newMSE, newObjective = iterate(i, j, 0.78)\n",
    "            itera += 1\n",
    "            print(\"MSE after \" + str(itera) + \" iterations = \" + str(newMSE))\n",
    "            \n",
    "            # Break the loop if maximum number of iterations reached\n",
    "            if itera == 100:\n",
    "                break\n",
    "        \n",
    "        # Calculate MSE on the test data\n",
    "        msev = mseValidate()\n",
    "        pairs.append((msev, i, j))\n",
    "        print(\"MSE on test data = \" + str(msev), 'MSE on train data: ', newMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3.033369360703887, 1, 9), (3.0336400431759603, 2, 9), (3.033987729055787, 1, 8), (3.0342888951331837, 2, 8), (3.035230490333241, 0, 9), (3.0352734667980723, 1, 7), (3.035317365711952, 3, 9), (3.03560744068551, 2, 7), (3.035821592820544, 0, 8), (3.036000730854622, 3, 8)]\n"
     ]
    }
   ],
   "source": [
    "# sort pairs by mse\n",
    "pairs.sort()\n",
    "\n",
    "print(pairs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE after 1 iterations = 2.964324216680804\n",
      "MSE on test data = 3.0603090612938795 MSE on train data:  2.8010752933263463\n",
      "MSE after 2 iterations = 2.8010752933263463\n",
      "MSE on test data = 3.038502818055278 MSE on train data:  2.7751090158180425\n",
      "MSE after 3 iterations = 2.7751090158180425\n",
      "MSE on test data = 3.0346492696801435 MSE on train data:  2.770222810597672\n",
      "MSE after 4 iterations = 2.770222810597672\n",
      "MSE on test data = 3.033820087676113 MSE on train data:  2.7691980152341418\n",
      "MSE after 5 iterations = 2.7691980152341418\n",
      "MSE on test data = 3.0335852709066202 MSE on train data:  2.7689501988237657\n",
      "MSE after 6 iterations = 2.7689501988237657\n",
      "MSE on test data = 3.033498915319792 MSE on train data:  2.768876939362853\n",
      "MSE after 7 iterations = 2.768876939362853\n",
      "MSE on test data = 3.033461033195304 MSE on train data:  2.768848545271122\n",
      "MSE after 8 iterations = 2.768848545271122\n",
      "MSE on test data = 3.0334424431723503 MSE on train data:  2.768833632473361\n",
      "MSE after 9 iterations = 2.768833632473361\n",
      "MSE on test data = 3.0334323766982574 MSE on train data:  2.768823471043123\n",
      "MSE after 10 iterations = 2.768823471043123\n",
      "MSE on test data = 3.0334262626783848 MSE on train data:  2.768815243280248\n",
      "MSE after 11 iterations = 2.768815243280248\n",
      "MSE on test data = 3.033422036582421 MSE on train data:  2.768807911203306\n",
      "MSE after 12 iterations = 2.768807911203306\n",
      "MSE on test data = 3.0334187440614264 MSE on train data:  2.7688010524977464\n",
      "MSE after 13 iterations = 2.7688010524977464\n",
      "MSE on test data = 3.0334159397129508 MSE on train data:  2.768794482854854\n",
      "MSE after 14 iterations = 2.768794482854854\n",
      "MSE on test data = 3.0334134138981366 MSE on train data:  2.7687881172394713\n",
      "MSE after 15 iterations = 2.7687881172394713\n",
      "MSE on test data = 3.033411066506078 MSE on train data:  2.7687819141191747\n",
      "MSE after 16 iterations = 2.7687819141191747\n",
      "MSE on test data = 3.033408848443307 MSE on train data:  2.7687758517159513\n",
      "MSE after 17 iterations = 2.7687758517159513\n",
      "MSE on test data = 3.0334067345246964 MSE on train data:  2.7687699175228864\n",
      "MSE after 18 iterations = 2.7687699175228864\n",
      "MSE on test data = 3.0334047109098132 MSE on train data:  2.768764103558105\n",
      "MSE after 19 iterations = 2.768764103558105\n",
      "MSE on test data = 3.033402769260331 MSE on train data:  2.7687584041638007\n",
      "MSE after 20 iterations = 2.7687584041638007\n",
      "MSE on test data = 3.0334009040019687 MSE on train data:  2.768752814957972\n",
      "MSE after 21 iterations = 2.768752814957972\n",
      "MSE on test data = 3.033399111022069 MSE on train data:  2.7687473323149763\n",
      "MSE after 22 iterations = 2.7687473323149763\n",
      "MSE on test data = 3.0333973870339497 MSE on train data:  2.7687419530945627\n",
      "MSE after 23 iterations = 2.7687419530945627\n",
      "MSE on test data = 3.033395729256311 MSE on train data:  2.7687366744923123\n",
      "MSE after 24 iterations = 2.7687366744923123\n",
      "MSE on test data = 3.033394135241725 MSE on train data:  2.7687314939494136\n",
      "MSE after 25 iterations = 2.7687314939494136\n",
      "MSE on test data = 3.0333926027797795 MSE on train data:  2.7687264090955632\n",
      "MSE after 26 iterations = 2.7687264090955632\n",
      "MSE on test data = 3.03339112983795 MSE on train data:  2.7687214177098967\n",
      "MSE after 27 iterations = 2.7687214177098967\n",
      "MSE on test data = 3.0333897145230684 MSE on train data:  2.768716517693127\n",
      "MSE after 28 iterations = 2.768716517693127\n",
      "MSE on test data = 3.0333883550547873 MSE on train data:  2.768711707046876\n",
      "MSE after 29 iterations = 2.768711707046876\n",
      "MSE on test data = 3.0333870497463624 MSE on train data:  2.7687069838583174\n",
      "MSE after 30 iterations = 2.7687069838583174\n",
      "MSE on test data = 3.0333857969905136 MSE on train data:  2.768702346287945\n",
      "MSE after 31 iterations = 2.768702346287945\n",
      "MSE on test data = 3.0333845952483514 MSE on train data:  2.7686977925607046\n",
      "MSE after 32 iterations = 2.7686977925607046\n",
      "MSE on test data = 3.0333834430411972 MSE on train data:  2.7686933209583824\n",
      "MSE after 33 iterations = 2.7686933209583824\n",
      "MSE on test data = 3.033382338943859 MSE on train data:  2.768688929813936\n",
      "MSE after 34 iterations = 2.768688929813936\n",
      "MSE on test data = 3.033381281579393 MSE on train data:  2.768684617507004\n",
      "MSE after 35 iterations = 2.768684617507004\n",
      "MSE on test data = 3.0333802696149426 MSE on train data:  2.76868038246014\n",
      "MSE after 36 iterations = 2.76868038246014\n",
      "MSE on test data = 3.03337930175841 MSE on train data:  2.7686762231357065\n",
      "MSE after 37 iterations = 2.7686762231357065\n",
      "MSE on test data = 3.0333783767556737 MSE on train data:  2.768672138033705\n",
      "MSE after 38 iterations = 2.768672138033705\n",
      "MSE on test data = 3.033377493388221 MSE on train data:  2.7686681256894983\n",
      "MSE after 39 iterations = 2.7686681256894983\n",
      "MSE on test data = 3.033376650471277 MSE on train data:  2.7686641846719815\n",
      "MSE after 40 iterations = 2.7686641846719815\n",
      "MSE on test data = 3.0333758468522984 MSE on train data:  2.768660313582468\n",
      "MSE after 41 iterations = 2.768660313582468\n",
      "MSE on test data = 3.0333750814094933 MSE on train data:  2.768656511053349\n",
      "MSE after 42 iterations = 2.768656511053349\n",
      "MSE on test data = 3.0333743530504806 MSE on train data:  2.768652775746453\n",
      "MSE after 43 iterations = 2.768652775746453\n",
      "MSE on test data = 3.033373660711456 MSE on train data:  2.768649106352935\n",
      "MSE after 44 iterations = 2.768649106352935\n",
      "MSE on test data = 3.033373003356005 MSE on train data:  2.768645501591812\n",
      "MSE after 45 iterations = 2.768645501591812\n",
      "MSE on test data = 3.0333723799744177 MSE on train data:  2.7686419602091648\n",
      "MSE after 46 iterations = 2.7686419602091648\n",
      "MSE on test data = 3.0333717895827377 MSE on train data:  2.768638480977768\n",
      "MSE after 47 iterations = 2.768638480977768\n",
      "MSE on test data = 3.033371231222079 MSE on train data:  2.768635062695811\n",
      "MSE after 48 iterations = 2.768635062695811\n",
      "MSE on test data = 3.0333707039579787 MSE on train data:  2.7686317041870114\n",
      "MSE after 49 iterations = 2.7686317041870114\n",
      "MSE on test data = 3.033370206879652 MSE on train data:  2.768628404299287\n",
      "MSE after 50 iterations = 2.768628404299287\n",
      "MSE on test data = 3.033369739099364 MSE on train data:  2.768625161904569\n",
      "MSE after 51 iterations = 2.768625161904569\n",
      "MSE on test data = 3.0333692997519464 MSE on train data:  2.7686219758982498\n",
      "MSE after 52 iterations = 2.7686219758982498\n",
      "MSE on test data = 3.033368887994067 MSE on train data:  2.7686188451983065\n",
      "MSE after 53 iterations = 2.7686188451983065\n",
      "MSE on test data = 3.033368503003966 MSE on train data:  2.7686157687453306\n",
      "MSE after 54 iterations = 2.7686157687453306\n",
      "MSE on test data = 3.0333681439804736 MSE on train data:  2.768612745501579\n",
      "MSE after 55 iterations = 2.768612745501579\n",
      "MSE on test data = 3.033367810142929 MSE on train data:  2.768609774450593\n",
      "MSE after 56 iterations = 2.768609774450593\n",
      "MSE on test data = 3.0333675007304555 MSE on train data:  2.768606854596934\n",
      "MSE after 57 iterations = 2.768606854596934\n",
      "MSE on test data = 3.0333672150015936 MSE on train data:  2.7686039849654427\n",
      "MSE after 58 iterations = 2.7686039849654427\n",
      "MSE on test data = 3.033366952233652 MSE on train data:  2.7686011646009705\n",
      "MSE after 59 iterations = 2.7686011646009705\n",
      "MSE on test data = 3.033366711722467 MSE on train data:  2.7685983925678808\n",
      "MSE after 60 iterations = 2.7685983925678808\n",
      "MSE on test data = 3.033366492781861 MSE on train data:  2.7685956679496986\n",
      "MSE after 61 iterations = 2.7685956679496986\n",
      "MSE on test data = 3.0333662947431645 MSE on train data:  2.7685929898486896\n",
      "MSE after 62 iterations = 2.7685929898486896\n",
      "MSE on test data = 3.033366116954967 MSE on train data:  2.768590357385166\n",
      "MSE after 63 iterations = 2.768590357385166\n",
      "MSE on test data = 3.0333659587823574 MSE on train data:  2.768587769697714\n",
      "MSE after 64 iterations = 2.768587769697714\n",
      "MSE on test data = 3.033365819606967 MSE on train data:  2.76858522594223\n",
      "MSE after 65 iterations = 2.76858522594223\n",
      "MSE on test data = 3.033365698826269 MSE on train data:  2.768582725291752\n",
      "MSE after 66 iterations = 2.768582725291752\n",
      "MSE on test data = 3.0333655958532284 MSE on train data:  2.7685802669362363\n",
      "MSE after 67 iterations = 2.7685802669362363\n",
      "MSE on test data = 3.033365510116096 MSE on train data:  2.768577850081873\n",
      "MSE after 68 iterations = 2.768577850081873\n",
      "MSE on test data = 3.0333654410578688 MSE on train data:  2.768575473951205\n",
      "MSE after 69 iterations = 2.768575473951205\n",
      "MSE on test data = 3.0333653881360303 MSE on train data:  2.768573137782188\n",
      "MSE after 70 iterations = 2.768573137782188\n",
      "MSE on test data = 3.033365350822122 MSE on train data:  2.768570840828293\n",
      "MSE after 71 iterations = 2.768570840828293\n",
      "MSE on test data = 3.0333653286014712 MSE on train data:  2.768568582358271\n",
      "MSE after 72 iterations = 2.768568582358271\n",
      "MSE on test data = 3.03336532097293 MSE on train data:  2.768566361655388\n",
      "MSE after 73 iterations = 2.768566361655388\n",
      "MSE on test data = 3.0333653274483234 MSE on train data:  2.768564178017344\n",
      "MSE after 74 iterations = 2.768564178017344\n",
      "MSE on test data = 3.0333653475523445 MSE on train data:  2.7685620307562355\n",
      "MSE after 75 iterations = 2.7685620307562355\n",
      "MSE on test data = 3.0333653808222008 MSE on train data:  2.7685599191976165\n",
      "MSE after 76 iterations = 2.7685599191976165\n",
      "MSE on test data = 3.033365426807248 MSE on train data:  2.7685578426808397\n",
      "MSE after 77 iterations = 2.7685578426808397\n",
      "MSE on test data = 3.0333654850687357 MSE on train data:  2.7685558005584627\n",
      "MSE after 78 iterations = 2.7685558005584627\n",
      "MSE on test data = 3.0333655551794965 MSE on train data:  2.7685537921960277\n",
      "MSE after 79 iterations = 2.7685537921960277\n",
      "MSE on test data = 3.0333656367237767 MSE on train data:  2.7685518169717094\n",
      "MSE after 80 iterations = 2.7685518169717094\n",
      "MSE on test data = 3.033365729296783 MSE on train data:  2.7685498742762418\n",
      "MSE after 81 iterations = 2.7685498742762418\n",
      "MSE on test data = 3.0333658325045003 MSE on train data:  2.768547963512384\n",
      "MSE after 82 iterations = 2.768547963512384\n",
      "MSE on test data = 3.0333659459635043 MSE on train data:  2.7685460840948495\n",
      "MSE after 83 iterations = 2.7685460840948495\n",
      "MSE on test data = 3.0333660693006173 MSE on train data:  2.7685442354501246\n",
      "MSE after 84 iterations = 2.7685442354501246\n",
      "MSE on test data = 3.033366202152629 MSE on train data:  2.76854241701605\n",
      "MSE after 85 iterations = 2.76854241701605\n",
      "MSE on test data = 3.033366344166099 MSE on train data:  2.768540628241428\n",
      "MSE after 86 iterations = 2.768540628241428\n",
      "MSE on test data = 3.033366494997199 MSE on train data:  2.7685388685864716\n",
      "MSE after 87 iterations = 2.7685388685864716\n",
      "MSE on test data = 3.033366654311307 MSE on train data:  2.7685371375216072\n",
      "MSE after 88 iterations = 2.7685371375216072\n",
      "MSE on test data = 3.033366821782962 MSE on train data:  2.76853543452821\n",
      "MSE after 89 iterations = 2.76853543452821\n",
      "MSE on test data = 3.0333669970955075 MSE on train data:  2.768533759097591\n",
      "MSE after 90 iterations = 2.768533759097591\n",
      "MSE on test data = 3.0333671799409005 MSE on train data:  2.7685321107310976\n",
      "MSE after 91 iterations = 2.7685321107310976\n",
      "MSE on test data = 3.0333673700195263 MSE on train data:  2.7685304889401947\n",
      "MSE after 92 iterations = 2.7685304889401947\n",
      "MSE on test data = 3.033367567040116 MSE on train data:  2.7685288932458483\n",
      "MSE after 93 iterations = 2.7685288932458483\n",
      "MSE on test data = 3.0333677707191744 MSE on train data:  2.7685273231783403\n",
      "MSE after 94 iterations = 2.7685273231783403\n",
      "MSE on test data = 3.0333679807812395 MSE on train data:  2.768525778277263\n",
      "MSE after 95 iterations = 2.768525778277263\n",
      "MSE on test data = 3.033368196958411 MSE on train data:  2.7685242580914466\n",
      "MSE after 96 iterations = 2.7685242580914466\n",
      "MSE on test data = 3.033368418990151 MSE on train data:  2.7685227621783124\n",
      "MSE after 97 iterations = 2.7685227621783124\n",
      "MSE on test data = 3.033368646623287 MSE on train data:  2.7685212901040255\n",
      "MSE after 98 iterations = 2.7685212901040255\n",
      "MSE on test data = 3.033368879611649 MSE on train data:  2.768519841443331\n",
      "MSE after 99 iterations = 2.768519841443331\n",
      "MSE on test data = 3.0333691177160214 MSE on train data:  2.768518415779314\n",
      "MSE after 100 iterations = 2.768518415779314\n",
      "MSE on test data = 3.033369360703887 MSE on train data:  2.768517012702907\n"
     ]
    }
   ],
   "source": [
    "# Initialize betaU and betaI dictionaries\n",
    "betaU = {}\n",
    "betaI = {}\n",
    "\n",
    "# Set initial values for betaU and betaI\n",
    "for u in hoursPerUser:\n",
    "    betaU[u] = 0\n",
    "\n",
    "for g in hoursPerItem:\n",
    "    betaI[g] = 0\n",
    "\n",
    "alpha = globalAverage \n",
    "\n",
    "mse, objective = (100, 100)\n",
    "newMSE, newObjective = iterate(1, 9, 0.78)\n",
    "itera = 0\n",
    "\n",
    "# Perform iterations until convergence or maximum number of iterations reached\n",
    "while itera < 10 or objective - newObjective > 0.01:\n",
    "    mse, objective = newMSE, newObjective\n",
    "    newMSE, newObjective = iterate(1, 9, 0.78)\n",
    "    itera += 1\n",
    "    print(\"MSE after \" + str(itera) + \" iterations = \" + str(mse))\n",
    "    \n",
    "    # Calculate MSE on the test data\n",
    "    mse = mseValidate()\n",
    "    print(\"MSE on test data = \" + str(mse), 'MSE on train data: ', newMSE)\n",
    "    \n",
    "    # Break the loop if maximum number of iterations reached\n",
    "    if itera == 100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data test output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a7cd55-1f58-42a5-8c35-4debf80a3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"./Data/pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    if u in betaU and g in betaI:\n",
    "        pred = predict(u,g)\n",
    "    elif u in betaU and g not in betaI:\n",
    "        pred = alpha + betaU[u] +np.mean([b for b in betaI.values()])\n",
    "    elif u not in betaU and g in betaI:\n",
    "        pred = alpha + betaI[g] + np.mean([b for b in betaU.values()])\n",
    "    else:\n",
    "        pred = globalAverage\n",
    "   \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
